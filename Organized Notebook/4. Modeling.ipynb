{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5551965-d884-410f-9e33-f663e3a66a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from pyswarm import pso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb32d3-41ff-42c3-94a3-d587ae42ac8c",
   "metadata": {},
   "source": [
    "### Random Forest (without feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1db0e38-5284-4462-a61e-a3eeea90db7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Combined Features:\n",
      "Accuracy (10-fold CV): 0.8624 ± 0.0148\n",
      "F1 Score (10-fold CV): 0.8144 ± 0.0207\n",
      "ROC-AUC (10-fold CV): 0.9276 ± 0.0096\n",
      "Precision (10-fold CV): 0.8459 ± 0.0210\n",
      "Recall (10-fold CV): 0.7851 ± 0.0218\n",
      "--------------------------------------------------\n",
      "Results for Radiomic Features:\n",
      "Accuracy (10-fold CV): 0.8113 ± 0.0161\n",
      "F1 Score (10-fold CV): 0.7514 ± 0.0197\n",
      "ROC-AUC (10-fold CV): 0.8811 ± 0.0109\n",
      "Precision (10-fold CV): 0.7626 ± 0.0295\n",
      "Recall (10-fold CV): 0.7416 ± 0.0275\n",
      "--------------------------------------------------\n",
      "Results for PyLidc Features:\n",
      "Accuracy (10-fold CV): 0.8736 ± 0.0122\n",
      "F1 Score (10-fold CV): 0.8337 ± 0.0163\n",
      "ROC-AUC (10-fold CV): 0.9378 ± 0.0102\n",
      "Precision (10-fold CV): 0.8438 ± 0.0194\n",
      "Recall (10-fold CV): 0.8241 ± 0.0200\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate_dataset(df, dataset_name):\n",
    "    # Classify the malignancy (0 = benign, 1 = malignant)\n",
    "    df['malignancy'] = df['malignancy'].replace({1: 0, 2: 0, 4: 1, 5: 1})  \n",
    "\n",
    "    # Separate Features and Target\n",
    "    X = df.drop('malignancy', axis=1)  # Features\n",
    "    y = df['malignancy']  # Target\n",
    "\n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize Random Forest Classifier\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Define multiple metrics to evaluate\n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'f1': make_scorer(f1_score),\n",
    "        'roc_auc': 'roc_auc',\n",
    "        'precision': make_scorer(precision_score),\n",
    "        'recall': make_scorer(recall_score)\n",
    "    }\n",
    "\n",
    "    # Perform 10-fold cross-validation with multiple metrics\n",
    "    cv_results = cross_validate(rf, X_train, y_train, cv=10, scoring=scoring, return_train_score=False)\n",
    "\n",
    "    # Print the mean and standard deviation of each metric\n",
    "    print(f\"Results for {dataset_name}:\")\n",
    "    print(f\"Accuracy (10-fold CV): {cv_results['test_accuracy'].mean():.4f} ± {cv_results['test_accuracy'].std():.4f}\")\n",
    "    print(f\"F1 Score (10-fold CV): {cv_results['test_f1'].mean():.4f} ± {cv_results['test_f1'].std():.4f}\")\n",
    "    print(f\"ROC-AUC (10-fold CV): {cv_results['test_roc_auc'].mean():.4f} ± {cv_results['test_roc_auc'].std():.4f}\")\n",
    "    print(f\"Precision (10-fold CV): {cv_results['test_precision'].mean():.4f} ± {cv_results['test_precision'].std():.4f}\")\n",
    "    print(f\"Recall (10-fold CV): {cv_results['test_recall'].mean():.4f} ± {cv_results['test_recall'].std():.4f}\")\n",
    "    print('-' * 50)\n",
    "\n",
    "# Load datasets\n",
    "df_combined = pd.read_csv('all_features_cleaned.csv')\n",
    "df_radiomic = pd.read_csv('radiomic_features.csv')\n",
    "df_pylidc = pd.read_csv('pylidc_features.csv')\n",
    "\n",
    "# Evaluate each dataset without feature selection\n",
    "evaluate_dataset(df_combined, \"Combined Features\")\n",
    "evaluate_dataset(df_radiomic, \"Radiomic Features\")\n",
    "evaluate_dataset(df_pylidc, \"PyLidc Features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d058eaa-144f-4950-acd0-802d972acd76",
   "metadata": {},
   "source": [
    "### Random Forest Classifier (with feature selection using Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a91eebc-f1b0-4034-b093-9d6023d5d71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features (importance > 0.01) for Combined Features: ['original_shape_Maximum2DDiameterSlice', 'original_shape_MeshVolume', 'original_shape_MinorAxisLength', 'original_shape_SurfaceArea', 'original_shape_VoxelVolume', 'original_firstorder_Minimum', 'original_glcm_Idn', 'original_glcm_Imc1', 'original_glcm_Imc2', 'original_gldm_DependenceNonUniformity', 'original_gldm_GrayLevelNonUniformity', 'original_gldm_SmallDependenceLowGrayLevelEmphasis', 'original_glrlm_GrayLevelNonUniformity', 'original_glrlm_RunLengthNonUniformity', 'original_glszm_GrayLevelNonUniformity', 'subtlety', 'calcification', 'margin', 'lobulation', 'spiculation', 'diameter', 'surface_area', 'volume', 'fourier_hist_bin_9']\n",
      "Results for Combined Features after feature selection:\n",
      "Accuracy (10-fold CV): 0.8724 ± 0.0137\n",
      "F1 Score (10-fold CV): 0.8294 ± 0.0182\n",
      "ROC-AUC (10-fold CV): 0.9375 ± 0.0112\n",
      "Precision (10-fold CV): 0.8540 ± 0.0241\n",
      "Recall (10-fold CV): 0.8065 ± 0.0227\n",
      "--------------------------------------------------\n",
      "Selected features (importance > 0.01) for Radiomic Features: ['original_shape_MajorAxisLength', 'original_shape_Maximum2DDiameterRow', 'original_shape_Maximum2DDiameterSlice', 'original_shape_MeshVolume', 'original_shape_MinorAxisLength', 'original_shape_SurfaceArea', 'original_shape_VoxelVolume', 'original_firstorder_Minimum', 'original_glcm_Idn', 'original_glcm_Imc1', 'original_glcm_Imc2', 'original_gldm_DependenceEntropy', 'original_gldm_GrayLevelNonUniformity', 'original_gldm_SmallDependenceLowGrayLevelEmphasis', 'original_glrlm_GrayLevelNonUniformity', 'original_glrlm_RunLengthNonUniformity', 'original_glszm_GrayLevelNonUniformity', 'original_glszm_LargeAreaHighGrayLevelEmphasis', 'original_glszm_SizeZoneNonUniformity', 'original_ngtdm_Coarseness', 'original_ngtdm_Strength', 'fourier_hist_bin_9']\n",
      "Results for Radiomic Features after feature selection:\n",
      "Accuracy (10-fold CV): 0.8131 ± 0.0168\n",
      "F1 Score (10-fold CV): 0.7553 ± 0.0206\n",
      "ROC-AUC (10-fold CV): 0.8796 ± 0.0125\n",
      "Precision (10-fold CV): 0.7614 ± 0.0298\n",
      "Recall (10-fold CV): 0.7500 ± 0.0238\n",
      "--------------------------------------------------\n",
      "Selected features (importance > 0.01) for PyLidc Features: ['subtlety', 'calcification', 'sphericity', 'margin', 'lobulation', 'spiculation', 'texture', 'diameter', 'surface_area', 'volume']\n",
      "Results for PyLidc Features after feature selection:\n",
      "Accuracy (10-fold CV): 0.8733 ± 0.0109\n",
      "F1 Score (10-fold CV): 0.8330 ± 0.0155\n",
      "ROC-AUC (10-fold CV): 0.9382 ± 0.0091\n",
      "Precision (10-fold CV): 0.8441 ± 0.0152\n",
      "Recall (10-fold CV): 0.8226 ± 0.0249\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate_dataset_with_feature_selection(df, dataset_name, threshold=0.01):\n",
    "    # Classify the malignancy (0 = benign, 1 = malignant)\n",
    "    df['malignancy'] = df['malignancy'].replace({1: 0, 2: 0, 4: 1, 5: 1})  \n",
    "\n",
    "    # Separate Features and Target\n",
    "    X = df.drop('malignancy', axis=1)  # Features\n",
    "    y = df['malignancy']  # Target\n",
    "\n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize Random Forest Classifier\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Get feature importances\n",
    "    feature_importances = rf.feature_importances_\n",
    "\n",
    "    # Create a DataFrame to store feature names and their importances\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': feature_importances\n",
    "    })\n",
    "\n",
    "    # Select features with importance greater than the threshold\n",
    "    selected_features = importance_df[importance_df['Importance'] > threshold]['Feature'].tolist()\n",
    "    print(f\"Selected features (importance > {threshold}) for {dataset_name}: {selected_features}\")\n",
    "\n",
    "    # Reduce the dataset to the selected features\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_test_selected = X_test[selected_features]\n",
    "\n",
    "    # Initialize a new Random Forest Classifier for the selected features\n",
    "    rf_selected = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Define multiple metrics to evaluate\n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'f1': make_scorer(f1_score),\n",
    "        'roc_auc': 'roc_auc',\n",
    "        'precision': make_scorer(precision_score),\n",
    "        'recall': make_scorer(recall_score)\n",
    "    }\n",
    "\n",
    "    # Perform 10-fold cross-validation with the selected features\n",
    "    cv_results = cross_validate(rf_selected, X_train_selected, y_train, cv=10, scoring=scoring, return_train_score=False)\n",
    "\n",
    "    # Print the mean and standard deviation of each metric\n",
    "    print(f\"Results for {dataset_name} after feature selection:\")\n",
    "    print(f\"Accuracy (10-fold CV): {cv_results['test_accuracy'].mean():.4f} ± {cv_results['test_accuracy'].std():.4f}\")\n",
    "    print(f\"F1 Score (10-fold CV): {cv_results['test_f1'].mean():.4f} ± {cv_results['test_f1'].std():.4f}\")\n",
    "    print(f\"ROC-AUC (10-fold CV): {cv_results['test_roc_auc'].mean():.4f} ± {cv_results['test_roc_auc'].std():.4f}\")\n",
    "    print(f\"Precision (10-fold CV): {cv_results['test_precision'].mean():.4f} ± {cv_results['test_precision'].std():.4f}\")\n",
    "    print(f\"Recall (10-fold CV): {cv_results['test_recall'].mean():.4f} ± {cv_results['test_recall'].std():.4f}\")\n",
    "    print('-' * 50)\n",
    "\n",
    "# Load datasets\n",
    "df_combined = pd.read_csv('all_features_cleaned.csv')\n",
    "df_radiomic = pd.read_csv('radiomic_features.csv')\n",
    "df_pylidc = pd.read_csv('pylidc_features.csv')\n",
    "\n",
    "# Evaluate each dataset with feature selection\n",
    "evaluate_dataset_with_feature_selection(df_combined, \"Combined Features\")\n",
    "evaluate_dataset_with_feature_selection(df_radiomic, \"Radiomic Features\")\n",
    "evaluate_dataset_with_feature_selection(df_pylidc, \"PyLidc Features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c473a742-fef3-4c75-9740-4cb487e02d50",
   "metadata": {},
   "source": [
    "### Random Forest Classifier (with feature selection using LASSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "960db938-5550-4c4b-bcbb-0f0f5191b010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features using Lasso for Combined Features: ['original_shape_Elongation', 'original_shape_Flatness', 'original_shape_LeastAxisLength', 'original_shape_MajorAxisLength', 'original_shape_Maximum2DDiameterColumn', 'original_shape_Maximum2DDiameterRow', 'original_shape_Maximum2DDiameterSlice', 'original_shape_Maximum3DDiameter', 'original_shape_MeshVolume', 'original_shape_MinorAxisLength', 'original_shape_Sphericity', 'original_shape_SurfaceArea', 'original_shape_SurfaceVolumeRatio', 'original_shape_VoxelVolume', 'original_firstorder_10Percentile', 'original_firstorder_90Percentile', 'original_firstorder_Energy', 'original_firstorder_Entropy', 'original_firstorder_InterquartileRange', 'original_firstorder_Kurtosis', 'original_firstorder_MeanAbsoluteDeviation', 'original_firstorder_Mean', 'original_firstorder_Median', 'original_firstorder_Minimum', 'original_firstorder_Range', 'original_firstorder_RobustMeanAbsoluteDeviation', 'original_firstorder_RootMeanSquared', 'original_firstorder_Skewness', 'original_firstorder_TotalEnergy', 'original_firstorder_Uniformity', 'original_firstorder_Variance', 'original_glcm_Autocorrelation', 'original_glcm_ClusterShade', 'original_glcm_ClusterTendency', 'original_glcm_Contrast', 'original_glcm_Correlation', 'original_glcm_DifferenceAverage', 'original_glcm_DifferenceEntropy', 'original_glcm_DifferenceVariance', 'original_glcm_Id', 'original_glcm_Idm', 'original_glcm_Idmn', 'original_glcm_Idn', 'original_glcm_Imc1', 'original_glcm_Imc2', 'original_glcm_InverseVariance', 'original_glcm_JointAverage', 'original_glcm_JointEnergy', 'original_glcm_JointEntropy', 'original_glcm_MCC', 'original_glcm_MaximumProbability', 'original_glcm_SumAverage', 'original_glcm_SumEntropy', 'original_glcm_SumSquares', 'original_gldm_DependenceEntropy', 'original_gldm_DependenceNonUniformity', 'original_gldm_DependenceNonUniformityNormalized', 'original_gldm_DependenceVariance', 'original_gldm_GrayLevelNonUniformity', 'original_gldm_GrayLevelVariance', 'original_gldm_HighGrayLevelEmphasis', 'original_gldm_LargeDependenceEmphasis', 'original_gldm_LargeDependenceHighGrayLevelEmphasis', 'original_gldm_LargeDependenceLowGrayLevelEmphasis', 'original_gldm_LowGrayLevelEmphasis', 'original_gldm_SmallDependenceEmphasis', 'original_gldm_SmallDependenceHighGrayLevelEmphasis', 'original_gldm_SmallDependenceLowGrayLevelEmphasis', 'original_glrlm_GrayLevelNonUniformity', 'original_glrlm_GrayLevelNonUniformityNormalized', 'original_glrlm_GrayLevelVariance', 'original_glrlm_HighGrayLevelRunEmphasis', 'original_glrlm_LongRunEmphasis', 'original_glrlm_LongRunHighGrayLevelEmphasis', 'original_glrlm_LongRunLowGrayLevelEmphasis', 'original_glrlm_RunEntropy', 'original_glrlm_RunLengthNonUniformity', 'original_glrlm_RunLengthNonUniformityNormalized', 'original_glrlm_RunPercentage', 'original_glrlm_RunVariance', 'original_glrlm_ShortRunEmphasis', 'original_glrlm_ShortRunHighGrayLevelEmphasis', 'original_glrlm_ShortRunLowGrayLevelEmphasis', 'original_glszm_GrayLevelNonUniformity', 'original_glszm_GrayLevelNonUniformityNormalized', 'original_glszm_GrayLevelVariance', 'original_glszm_HighGrayLevelZoneEmphasis', 'original_glszm_LargeAreaEmphasis', 'original_glszm_LargeAreaHighGrayLevelEmphasis', 'original_glszm_LargeAreaLowGrayLevelEmphasis', 'original_glszm_LowGrayLevelZoneEmphasis', 'original_glszm_SizeZoneNonUniformity', 'original_glszm_SizeZoneNonUniformityNormalized', 'original_glszm_SmallAreaEmphasis', 'original_glszm_SmallAreaHighGrayLevelEmphasis', 'original_glszm_SmallAreaLowGrayLevelEmphasis', 'original_glszm_ZoneEntropy', 'original_glszm_ZonePercentage', 'original_glszm_ZoneVariance', 'original_ngtdm_Busyness', 'original_ngtdm_Coarseness', 'original_ngtdm_Complexity', 'original_ngtdm_Contrast', 'original_ngtdm_Strength', 'subtlety', 'internalStructure', 'calcification', 'sphericity', 'margin', 'lobulation', 'spiculation', 'texture', 'diameter', 'surface_area', 'volume', 'fourier_hist_bin_0', 'fourier_hist_bin_2', 'fourier_hist_bin_3', 'fourier_hist_bin_4', 'fourier_hist_bin_5', 'fourier_hist_bin_6', 'fourier_hist_bin_7', 'fourier_hist_bin_8', 'fourier_hist_bin_9']\n",
      "Results for Combined Features after Lasso feature selection:\n",
      "Accuracy (10-fold CV): 0.8657 ± 0.0141\n",
      "F1 Score (10-fold CV): 0.8185 ± 0.0192\n",
      "ROC-AUC (10-fold CV): 0.9279 ± 0.0101\n",
      "Precision (10-fold CV): 0.8516 ± 0.0219\n",
      "Recall (10-fold CV): 0.7882 ± 0.0222\n",
      "--------------------------------------------------\n",
      "Selected features using Lasso for Radiomic Features: ['original_shape_Elongation', 'original_shape_Flatness', 'original_shape_LeastAxisLength', 'original_shape_MajorAxisLength', 'original_shape_Maximum2DDiameterColumn', 'original_shape_Maximum2DDiameterRow', 'original_shape_Maximum2DDiameterSlice', 'original_shape_Maximum3DDiameter', 'original_shape_MeshVolume', 'original_shape_MinorAxisLength', 'original_shape_Sphericity', 'original_shape_SurfaceArea', 'original_shape_SurfaceVolumeRatio', 'original_shape_VoxelVolume', 'original_firstorder_10Percentile', 'original_firstorder_90Percentile', 'original_firstorder_Energy', 'original_firstorder_Entropy', 'original_firstorder_InterquartileRange', 'original_firstorder_Kurtosis', 'original_firstorder_Maximum', 'original_firstorder_MeanAbsoluteDeviation', 'original_firstorder_Mean', 'original_firstorder_Median', 'original_firstorder_Minimum', 'original_firstorder_Range', 'original_firstorder_RobustMeanAbsoluteDeviation', 'original_firstorder_RootMeanSquared', 'original_firstorder_Skewness', 'original_firstorder_TotalEnergy', 'original_firstorder_Uniformity', 'original_firstorder_Variance', 'original_glcm_Autocorrelation', 'original_glcm_ClusterProminence', 'original_glcm_ClusterShade', 'original_glcm_ClusterTendency', 'original_glcm_Contrast', 'original_glcm_Correlation', 'original_glcm_DifferenceAverage', 'original_glcm_DifferenceEntropy', 'original_glcm_DifferenceVariance', 'original_glcm_Id', 'original_glcm_Idm', 'original_glcm_Idmn', 'original_glcm_Idn', 'original_glcm_Imc1', 'original_glcm_Imc2', 'original_glcm_InverseVariance', 'original_glcm_JointAverage', 'original_glcm_JointEnergy', 'original_glcm_JointEntropy', 'original_glcm_MCC', 'original_glcm_MaximumProbability', 'original_glcm_SumAverage', 'original_glcm_SumEntropy', 'original_glcm_SumSquares', 'original_gldm_DependenceEntropy', 'original_gldm_DependenceNonUniformity', 'original_gldm_DependenceNonUniformityNormalized', 'original_gldm_DependenceVariance', 'original_gldm_GrayLevelNonUniformity', 'original_gldm_GrayLevelVariance', 'original_gldm_HighGrayLevelEmphasis', 'original_gldm_LargeDependenceEmphasis', 'original_gldm_LargeDependenceHighGrayLevelEmphasis', 'original_gldm_LargeDependenceLowGrayLevelEmphasis', 'original_gldm_LowGrayLevelEmphasis', 'original_gldm_SmallDependenceEmphasis', 'original_gldm_SmallDependenceHighGrayLevelEmphasis', 'original_gldm_SmallDependenceLowGrayLevelEmphasis', 'original_glrlm_GrayLevelNonUniformity', 'original_glrlm_GrayLevelNonUniformityNormalized', 'original_glrlm_GrayLevelVariance', 'original_glrlm_HighGrayLevelRunEmphasis', 'original_glrlm_LongRunEmphasis', 'original_glrlm_LongRunHighGrayLevelEmphasis', 'original_glrlm_LongRunLowGrayLevelEmphasis', 'original_glrlm_LowGrayLevelRunEmphasis', 'original_glrlm_RunEntropy', 'original_glrlm_RunLengthNonUniformity', 'original_glrlm_RunLengthNonUniformityNormalized', 'original_glrlm_RunPercentage', 'original_glrlm_RunVariance', 'original_glrlm_ShortRunEmphasis', 'original_glrlm_ShortRunHighGrayLevelEmphasis', 'original_glrlm_ShortRunLowGrayLevelEmphasis', 'original_glszm_GrayLevelNonUniformity', 'original_glszm_GrayLevelNonUniformityNormalized', 'original_glszm_GrayLevelVariance', 'original_glszm_HighGrayLevelZoneEmphasis', 'original_glszm_LargeAreaEmphasis', 'original_glszm_LargeAreaHighGrayLevelEmphasis', 'original_glszm_LargeAreaLowGrayLevelEmphasis', 'original_glszm_LowGrayLevelZoneEmphasis', 'original_glszm_SizeZoneNonUniformity', 'original_glszm_SizeZoneNonUniformityNormalized', 'original_glszm_SmallAreaEmphasis', 'original_glszm_SmallAreaHighGrayLevelEmphasis', 'original_glszm_SmallAreaLowGrayLevelEmphasis', 'original_glszm_ZoneEntropy', 'original_glszm_ZonePercentage', 'original_glszm_ZoneVariance', 'original_ngtdm_Busyness', 'original_ngtdm_Coarseness', 'original_ngtdm_Complexity', 'original_ngtdm_Contrast', 'original_ngtdm_Strength', 'fourier_hist_bin_1', 'fourier_hist_bin_2', 'fourier_hist_bin_3', 'fourier_hist_bin_4', 'fourier_hist_bin_5', 'fourier_hist_bin_6', 'fourier_hist_bin_7', 'fourier_hist_bin_8', 'fourier_hist_bin_9']\n",
      "Results for Radiomic Features after Lasso feature selection:\n",
      "Accuracy (10-fold CV): 0.8136 ± 0.0180\n",
      "F1 Score (10-fold CV): 0.7532 ± 0.0215\n",
      "ROC-AUC (10-fold CV): 0.8820 ± 0.0126\n",
      "Precision (10-fold CV): 0.7687 ± 0.0325\n",
      "Recall (10-fold CV): 0.7393 ± 0.0246\n",
      "--------------------------------------------------\n",
      "Selected features using Lasso for PyLidc Features: ['subtlety', 'internalStructure', 'calcification', 'sphericity', 'margin', 'lobulation', 'spiculation', 'texture', 'diameter', 'surface_area', 'volume']\n",
      "Results for PyLidc Features after Lasso feature selection:\n",
      "Accuracy (10-fold CV): 0.8733 ± 0.0124\n",
      "F1 Score (10-fold CV): 0.8331 ± 0.0163\n",
      "ROC-AUC (10-fold CV): 0.9376 ± 0.0102\n",
      "Precision (10-fold CV): 0.8442 ± 0.0205\n",
      "Recall (10-fold CV): 0.8226 ± 0.0196\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "def evaluate_dataset_with_lasso(df, dataset_name, lasso_alpha=0.01):\n",
    "    \"\"\"\n",
    "    Standard function to evaluate Random Forest with 10-fold cross-validation\n",
    "    after selecting features using Lasso for feature selection.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing features and target\n",
    "    - dataset_name: String, name of the dataset (for printing results)\n",
    "    - lasso_alpha: Float, regularization strength for Lasso (default 0.01)\n",
    "    \n",
    "    Returns:\n",
    "    - Prints the performance metrics of the model after feature selection with Lasso\n",
    "    \"\"\"\n",
    "    # Classify the malignancy (0 = benign, 1 = malignant)\n",
    "    df['malignancy'] = df['malignancy'].replace({1: 0, 2: 0, 4: 1, 5: 1})  \n",
    "\n",
    "    # Separate Features and Target\n",
    "    X = df.drop('malignancy', axis=1)  # Features\n",
    "    y = df['malignancy']  # Target\n",
    "\n",
    "    # Standardize features for Lasso (important for regularization)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Apply Lasso for feature selection (L1 regularization)\n",
    "    lasso = LogisticRegression(penalty='l1', solver='liblinear', C=1/lasso_alpha, max_iter=1000)\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    # Get the non-zero coefficients (selected features)\n",
    "    selected_features_indices = lasso.coef_ != 0\n",
    "    selected_features = X.columns[selected_features_indices[0]]\n",
    "    \n",
    "    print(f\"Selected features using Lasso for {dataset_name}: {selected_features.tolist()}\")\n",
    "\n",
    "    # Reduce the dataset to the selected features\n",
    "    X_train_selected = X_train[:, selected_features_indices[0]]\n",
    "    X_test_selected = X_test[:, selected_features_indices[0]]\n",
    "\n",
    "    # Train a Random Forest Classifier on the selected features\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Define multiple metrics to evaluate\n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'f1': make_scorer(f1_score),\n",
    "        'roc_auc': 'roc_auc',\n",
    "        'precision': make_scorer(precision_score),\n",
    "        'recall': make_scorer(recall_score)\n",
    "    }\n",
    "\n",
    "    # Perform 10-fold cross-validation with the selected features\n",
    "    cv_results = cross_validate(rf, X_train_selected, y_train, cv=10, scoring=scoring, return_train_score=False)\n",
    "\n",
    "    # Print the mean and standard deviation of each metric\n",
    "    print(f\"Results for {dataset_name} after Lasso feature selection:\")\n",
    "    print(f\"Accuracy (10-fold CV): {cv_results['test_accuracy'].mean():.4f} ± {cv_results['test_accuracy'].std():.4f}\")\n",
    "    print(f\"F1 Score (10-fold CV): {cv_results['test_f1'].mean():.4f} ± {cv_results['test_f1'].std():.4f}\")\n",
    "    print(f\"ROC-AUC (10-fold CV): {cv_results['test_roc_auc'].mean():.4f} ± {cv_results['test_roc_auc'].std():.4f}\")\n",
    "    print(f\"Precision (10-fold CV): {cv_results['test_precision'].mean():.4f} ± {cv_results['test_precision'].std():.4f}\")\n",
    "    print(f\"Recall (10-fold CV): {cv_results['test_recall'].mean():.4f} ± {cv_results['test_recall'].std():.4f}\")\n",
    "    print('-' * 50)\n",
    "\n",
    "# Load datasets\n",
    "df_combined = pd.read_csv('all_features_cleaned.csv')\n",
    "df_radiomic = pd.read_csv('radiomic_features.csv')\n",
    "df_pylidc = pd.read_csv('pylidc_features.csv')\n",
    "\n",
    "# Evaluate each dataset with Lasso feature selection and Random Forest classification\n",
    "evaluate_dataset_with_lasso(df_combined, \"Combined Features\")\n",
    "evaluate_dataset_with_lasso(df_radiomic, \"Radiomic Features\")\n",
    "evaluate_dataset_with_lasso(df_pylidc, \"PyLidc Features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0e1b38-54a7-4ca9-b1ec-b7c7a52d5445",
   "metadata": {},
   "source": [
    "### Random Forest Classifier (with feature selection using PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb3bade3-0769-4ac2-aa16-56fff8e81e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components selected by PCA for Combined Features: 30\n",
      "Results for Combined Features after PCA feature selection:\n",
      "Accuracy (10-fold CV): 0.8621 ± 0.0086\n",
      "F1 Score (10-fold CV): 0.8148 ± 0.0096\n",
      "ROC-AUC (10-fold CV): 0.9275 ± 0.0104\n",
      "Precision (10-fold CV): 0.8437 ± 0.0218\n",
      "Recall (10-fold CV): 0.7882 ± 0.0107\n",
      "--------------------------------------------------\n",
      "Number of components selected by PCA for Radiomic Features: 24\n",
      "Results for Radiomic Features after PCA feature selection:\n",
      "Accuracy (10-fold CV): 0.8113 ± 0.0188\n",
      "F1 Score (10-fold CV): 0.7479 ± 0.0219\n",
      "ROC-AUC (10-fold CV): 0.8809 ± 0.0134\n",
      "Precision (10-fold CV): 0.7708 ± 0.0360\n",
      "Recall (10-fold CV): 0.7271 ± 0.0193\n",
      "--------------------------------------------------\n",
      "Number of components selected by PCA for PyLidc Features: 8\n",
      "Results for PyLidc Features after PCA feature selection:\n",
      "Accuracy (10-fold CV): 0.8683 ± 0.0162\n",
      "F1 Score (10-fold CV): 0.8304 ± 0.0223\n",
      "ROC-AUC (10-fold CV): 0.9321 ± 0.0100\n",
      "Precision (10-fold CV): 0.8213 ± 0.0169\n",
      "Recall (10-fold CV): 0.8402 ± 0.0332\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def evaluate_dataset_with_pca(df, dataset_name, n_components=0.95):\n",
    "    # Classify the malignancy (0 = benign, 1 = malignant)\n",
    "    df['malignancy'] = df['malignancy'].replace({1: 0, 2: 0, 4: 1, 5: 1})  \n",
    "\n",
    "    # Separate Features and Target\n",
    "    X = df.drop('malignancy', axis=1)  # Features\n",
    "    y = df['malignancy']  # Target\n",
    "\n",
    "    # Standardize features for PCA\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Apply PCA for dimensionality reduction\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    print(f\"Number of components selected by PCA for {dataset_name}: {X_train_pca.shape[1]}\")\n",
    "\n",
    "    # Train a Random Forest Classifier on the PCA-transformed features\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Define multiple metrics to evaluate\n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'f1': make_scorer(f1_score),\n",
    "        'roc_auc': 'roc_auc',\n",
    "        'precision': make_scorer(precision_score),\n",
    "        'recall': make_scorer(recall_score)\n",
    "    }\n",
    "\n",
    "    # Perform 10-fold cross-validation with the PCA components\n",
    "    cv_results = cross_validate(rf, X_train_pca, y_train, cv=10, scoring=scoring, return_train_score=False)\n",
    "\n",
    "    # Print the mean and standard deviation of each metric\n",
    "    print(f\"Results for {dataset_name} after PCA feature selection:\")\n",
    "    print(f\"Accuracy (10-fold CV): {cv_results['test_accuracy'].mean():.4f} ± {cv_results['test_accuracy'].std():.4f}\")\n",
    "    print(f\"F1 Score (10-fold CV): {cv_results['test_f1'].mean():.4f} ± {cv_results['test_f1'].std():.4f}\")\n",
    "    print(f\"ROC-AUC (10-fold CV): {cv_results['test_roc_auc'].mean():.4f} ± {cv_results['test_roc_auc'].std():.4f}\")\n",
    "    print(f\"Precision (10-fold CV): {cv_results['test_precision'].mean():.4f} ± {cv_results['test_precision'].std():.4f}\")\n",
    "    print(f\"Recall (10-fold CV): {cv_results['test_recall'].mean():.4f} ± {cv_results['test_recall'].std():.4f}\")\n",
    "    print('-' * 50)\n",
    "\n",
    "# Load datasets\n",
    "df_combined = pd.read_csv('all_features_cleaned.csv')\n",
    "df_radiomic = pd.read_csv('radiomic_features.csv')\n",
    "df_pylidc = pd.read_csv('pylidc_features.csv')\n",
    "\n",
    "# Evaluate each dataset with PCA feature selection and Random Forest classification\n",
    "evaluate_dataset_with_pca(df_combined, \"Combined Features\")\n",
    "evaluate_dataset_with_pca(df_radiomic, \"Radiomic Features\")\n",
    "evaluate_dataset_with_pca(df_pylidc, \"PyLidc Features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186b7a3-194b-4055-88d8-b80c29eb2af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
